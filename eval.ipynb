{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb0Fk5kf_u-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacb979a-d1b2-4769-9ede-e734447df984"
      },
      "source": [
        "!pip install scikit-surprise\n",
        "!pip install import-ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLrUzyn-_vAc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.metrics import ndcg_score, precision_score\n",
        "from surprise import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from full_notebook import Recommender, Env, UserMovieEmbedding"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZa-Pw8p_vCf"
      },
      "source": [
        "data = Dataset.load_builtin('ml-1m')\n",
        "\n",
        "df = pd.DataFrame(data.raw_ratings, columns = ['UserId', 'MovieId', 'Rating',  'Timestamp'], dtype='int32')\n",
        "df = df.astype('int32')\n",
        "users = df['UserId'].unique()\n",
        "items = df['MovieId'].unique()\n",
        "\n",
        "users_dict = np.load('user_dict.npy', allow_pickle=True).item()\n",
        "users_history_lens = np.load('users_histroy_len.npy')\n",
        "\n",
        "users_num = max(df[\"UserId\"])+1\n",
        "items_num = max(df[\"MovieId\"])+1\n",
        "\n",
        "eval_users_num = int(users_num * 0.2)\n",
        "eval_items_num = items_num\n",
        "\n",
        "eval_users_dict = {k:users_dict[k] for k in range(users_num-eval_users_num, users_num)}\n",
        "eval_users_history_lens = users_history_lens[-eval_users_num:]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS8GiFec_vEv"
      },
      "source": [
        "def evaluate(recommender, env, top_k=False):\n",
        "  episode_rewards = []\n",
        "  steps = 0\n",
        "  mean_precision = 0\n",
        "  mean_ndcg = 0\n",
        "  user_id, items_ids, all_items_ids, done = env.reset()\n",
        "  hit_miss = []\n",
        "  EMBEDDING_DIM = 100\n",
        "  embedding_network = UserMovieEmbedding(users_num,items_num, EMBEDDING_DIM)\n",
        "  all_items_embeddings = embedding_network.m(torch.LongTensor(list(all_items_ids)))\n",
        "\n",
        "  while not done:\n",
        "    # Observe current state & Find action\n",
        "    user_embedding = embedding_network.u(torch.LongTensor([user_id]))\n",
        "    item_embeddings = embedding_network.m(torch.LongTensor(list(items_ids)))\n",
        "\n",
        "    state = recommender.state_repr(item_embeddings.unsqueeze(1), user_embedding)\n",
        "\n",
        "    ## Action and recommended item\n",
        "    action = recommender.actor.local_network(state)\n",
        "    recommended_item = recommender.recommend_item(action, all_items_embeddings, all_items_ids, top_k=top_k)\n",
        "\n",
        "    # Calculate reward & observe new state (in env)\n",
        "    steps, next_items_ids, reward, done, recommended_item = env.step(recommended_item, steps, top_k=top_k)\n",
        "    print(steps, next_items_ids, reward, done, recommended_item)\n",
        "    if top_k:\n",
        "      correct_list = [1 if r > 0 else 0 for r in reward]\n",
        "      list_of_ones = [1] * top_k\n",
        "      mean_ndcg += ndcg_score([correct_list], [list_of_ones])\n",
        "      mean_precision +=  precision_score(correct_list, list_of_ones)  \n",
        "      hit_miss += correct_list\n",
        "    else:\n",
        "      hit_miss += [1 if reward > 0 else 0]\n",
        "\n",
        "    items_ids = next_items_ids\n",
        "    episode_rewards = episode_rewards + [np.sum(reward)]\n",
        "\n",
        "  if top_k:\n",
        "    return np.mean(episode_rewards), mean_precision/steps, mean_ndcg/steps\n",
        "\n",
        "  list_of_ones = [1]*steps\n",
        "\n",
        "  print(episode_rewards)\n",
        "  print(hit_miss)\n",
        "  return np.mean(episode_rewards), precision_score(hit_miss, list_of_ones), ndcg_score([hit_miss], [list_of_ones])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkEvBgd4_vGu"
      },
      "source": [
        "STATE_SIZE = 10\n",
        "MAX_EPISODE_NUM = 8000\n",
        "STATE_SIZE = 10"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jSrVOQ-_vJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ecd75a-5a72-4a52-8cd0-0015b424c857"
      },
      "source": [
        "sum_precision = 0\n",
        "sum_ndcg = 0\n",
        "TOP_K = 10\n",
        "\n",
        "for user_id in [4833]:#eval_users_dict.keys():\n",
        "    env = Env(eval_users_dict, users_history_lens, STATE_SIZE, fix_user_id=user_id)\n",
        "    recommender = Recommender (env, users, items, STATE_SIZE)\n",
        "    er, precision, ndcg = evaluate(recommender, env, top_k=TOP_K)\n",
        "    sum_precision += precision\n",
        "    sum_ndcg += ndcg\n",
        "\n",
        "print(f'precision@{TOP_K} : {sum_precision/len(eval_users_dict)}, ndcg@{TOP_K} : {sum_ndcg/len(eval_users_dict)}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [1.0, 1.0, 1.0, 0.0, 1.0, -0.5, 0.5, 0.5, 1.0, 1.0] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "2 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "3 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "4 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "5 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "6 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "7 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "8 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "9 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] False {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "10 [2709.0, 928.0, 1197.0, 1950.0, 1282.0, 2792.0, 1954.0, 2724.0, 1278.0, 260.0] [0.5, 0.5, 0.5, 0.0, 0.5, -0.25, 0.25, 0.25, 0.5, 0.5] True {928.0, 1282.0, 1954.0, 2724.0, 260.0, 2792.0, 1197.0, 2709.0, 1278.0, 1950.0}\n",
            "precision@10 : 0.000662251655629139, ndcg@10 : 0.0007610994563982076\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}